{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-01 14:40:56.036840: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-11-01 14:40:56.101186: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2022-11-01 14:40:56.117990: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2022-11-01 14:40:56.466846: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/home/rayed/anaconda3/envs/tf/lib/:/home/rayed/anaconda3/envs/tf/lib/\n",
      "2022-11-01 14:40:56.466883: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/home/rayed/anaconda3/envs/tf/lib/:/home/rayed/anaconda3/envs/tf/lib/\n",
      "2022-11-01 14:40:56.466887: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/bin/zsh: /home/rayed/anaconda3/envs/tf/lib/libtinfo.so.6: no version information available (required by /usr/bin/zsh)\n",
      "wget: /home/rayed/anaconda3/envs/tf/lib/libuuid.so.1: no version information available (required by wget)\n",
      "--2022-11-01 14:41:32--  http://storage.googleapis.com/download.tensorflow.org/data/spa-eng.zip\n",
      "Resolving storage.googleapis.com (storage.googleapis.com)... 2404:6800:4001:809::2010, 2404:6800:4001:80a::2010, 2404:6800:4001:806::2010, ...\n",
      "Connecting to storage.googleapis.com (storage.googleapis.com)|2404:6800:4001:809::2010|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 2638744 (2.5M) [application/zip]\n",
      "Saving to: ‘spa-eng.zip’\n",
      "\n",
      "spa-eng.zip         100%[===================>]   2.52M  3.82MB/s    in 0.7s    \n",
      "\n",
      "2022-11-01 14:41:33 (3.82 MB/s) - ‘spa-eng.zip’ saved [2638744/2638744]\n",
      "\n",
      "/usr/bin/zsh: /home/rayed/anaconda3/envs/tf/lib/libtinfo.so.6: no version information available (required by /usr/bin/zsh)\n"
     ]
    }
   ],
   "source": [
    "!wget http://storage.googleapis.com/download.tensorflow.org/data/spa-eng.zip\n",
    "!unzip -q spa-eng.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/bin/zsh: /home/rayed/anaconda3/envs/tf/lib/libtinfo.so.6: no version information available (required by /usr/bin/zsh)\n",
      "Can you meet tonight?\t¿Te puedes juntar esta noche?\n",
      "She gave in to the temptation.\tElla cedió a la tentación.\n",
      "I don't have a sword.\tYo no tengo una espada.\n",
      "Look out for bees.\tCuidado con las abejas.\n",
      "Tom went out to look for something to eat.\tTom salió a buscar algo para comer.\n",
      "You don't usually do that by yourself, do you?\tNormalmente no lo haces tú mismo, ¿verdad?\n",
      "Tom got here an hour before Mary.\tTom llegó aquí una hora antes que Mary.\n",
      "If it were not for air, we could not live on the earth.\tSi no fuera por el aire, no podríamos vivir en la Tierra.\n",
      "What did you hope to accomplish?\t¿Qué esperabas lograr?\n",
      "He will also go.\tÉl también irá.\n"
     ]
    }
   ],
   "source": [
    "!shuf -n 10 spa-eng/spa.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_pairs = []\n",
    "for line in open('spa-eng/spa.txt').readlines():\n",
    "    eng, spa = line.strip('\\n').split('\\t')\n",
    "    spa = '[start] ' + spa + ' [end]'\n",
    "    text_pairs.append((eng, spa))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('That castle is beautiful.', '[start] Ese castillo es hermoso. [end]')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "random.choice(text_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "118964"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(text_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "random.shuffle(text_pairs)\n",
    "num_val_samples = int(0.15 * len(text_pairs))\n",
    "num_train_samples = len(text_pairs) - 2 * num_val_samples\n",
    "train_pairs = text_pairs[:num_train_samples]\n",
    "val_pairs = text_pairs[num_train_samples:num_train_samples + num_val_samples]\n",
    "test_pairs = text_pairs[num_train_samples + num_val_samples:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(83276, 17844, 17844)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_pairs), len(val_pairs), len(test_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-01 20:20:49.447038: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-01 20:20:49.449837: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-01 20:20:49.449918: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-01 20:20:49.450300: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-11-01 20:20:49.451284: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-01 20:20:49.451380: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-01 20:20:49.451433: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-01 20:20:49.721858: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-01 20:20:49.721943: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-01 20:20:49.721989: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-01 20:20:49.722036: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 21681 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090 Ti, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "import re\n",
    "\n",
    "strip_chars = string.punctuation + \"¿\"\n",
    "strip_chars = strip_chars.replace('[', '')\n",
    "strip_chars = strip_chars.replace(']', '')\n",
    "\n",
    "vocab_size = 15_000\n",
    "sequence_length = 20\n",
    "def custom_standardization(input_string):\n",
    "    lowercase = tf.strings.lower(input_string)\n",
    "    return tf.strings.regex_replace(lowercase, f'[{re.escape(strip_chars)}]', '')\n",
    "\n",
    "source_vectorization = keras.layers.TextVectorization(\n",
    "    max_tokens = vocab_size,\n",
    "    output_mode = 'int',\n",
    "    output_sequence_length = sequence_length\n",
    ")\n",
    "target_vectorization = keras.layers.TextVectorization(\n",
    "    max_tokens = vocab_size,\n",
    "    output_mode = 'int',\n",
    "    output_sequence_length = sequence_length + 1,\n",
    "    standardize = custom_standardization\n",
    ")\n",
    "\n",
    "train_english_texts = [pair[0] for pair in train_pairs]\n",
    "train_spanish_texts = [pair[1] for pair in train_pairs]\n",
    "source_vectorization.adapt(train_english_texts)\n",
    "target_vectorization.adapt(train_spanish_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "\n",
    "def format_dataset(eng, spa):\n",
    "    eng = source_vectorization(eng)\n",
    "    spa = target_vectorization(spa)\n",
    "    return ({\n",
    "        'english': eng,\n",
    "        'spanish': spa[:, :-1]\n",
    "    }, spa[:, 1:])\n",
    "\n",
    "def make_dataset(pairs):\n",
    "    eng_texts, spa_texts = zip(*pairs)\n",
    "    eng_texts = list(eng_texts)\n",
    "    spa_texts = list(spa_texts)\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((eng_texts, spa_texts))\n",
    "    dataset = dataset.batch(batch_size)\n",
    "    dataset = dataset.map(format_dataset, num_parallel_calls=8)\n",
    "    dataset = dataset.shuffle(2048).prefetch(16).cache()\n",
    "    return dataset\n",
    "\n",
    "train_ds = make_dataset(train_pairs)\n",
    "val_ds = make_dataset(val_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs['english'].shape: (64, 20)\n",
      "inputs['spanish'].shape: (64, 20)\n",
      "targets.shape: (64, 20)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-01 21:10:14.313725: W tensorflow/core/kernels/data/cache_dataset_ops.cc:856] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    }
   ],
   "source": [
    "for inputs, targets in train_ds.take(1):\n",
    "    print(f\"inputs['english'].shape: {inputs['english'].shape}\")\n",
    "    print(f\"inputs['spanish'].shape: {inputs['spanish'].shape}\")\n",
    "    print(f\"targets.shape: {targets.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_dim = 256\n",
    "latent_dim = 1024\n",
    "\n",
    "source = keras.Input(shape=[None, ], dtype='int64', name='english')\n",
    "x = keras.layers.Embedding(vocab_size, embed_dim, mask_zero=True)(source)\n",
    "encoded_source = keras.layers.Bidirectional(\n",
    "    keras.layers.GRU(latent_dim), merge_mode='sum'\n",
    ")(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "past_target = keras.Input(shape=[None, ], dtype='int64', name='spanish')\n",
    "x = keras.layers.Embedding(vocab_size, embed_dim, mask_zero=True)(past_target)\n",
    "decoder_gru = keras.layers.GRU(latent_dim, return_sequences=True)\n",
    "x = decoder_gru(x, initial_state=encoded_source)\n",
    "x = keras.layers.Dropout(0.5)(x)\n",
    "target_next_step = keras.layers.Dense(vocab_size, activation='softmax')(x)\n",
    "seq2seq_rnn = keras.Model([source, past_target], target_next_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KerasTensor: shape=(None, 4, 10) dtype=float32 (created by layer 'dense_4')>"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input = keras.Input(shape=[4, 5])\n",
    "dense = keras.layers.Dense(10)\n",
    "dense(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-03 11:22:53.925413: W tensorflow/core/common_runtime/forward_type_inference.cc:332] Type inference failed. This indicates an invalid graph that escaped type checking. Error message: INVALID_ARGUMENT: expected compatible input types, but input 1:\n",
      "type_id: TFT_OPTIONAL\n",
      "args {\n",
      "  type_id: TFT_PRODUCT\n",
      "  args {\n",
      "    type_id: TFT_TENSOR\n",
      "    args {\n",
      "      type_id: TFT_INT32\n",
      "    }\n",
      "  }\n",
      "}\n",
      " is neither a subtype nor a supertype of the combined inputs preceding it:\n",
      "type_id: TFT_OPTIONAL\n",
      "args {\n",
      "  type_id: TFT_PRODUCT\n",
      "  args {\n",
      "    type_id: TFT_TENSOR\n",
      "    args {\n",
      "      type_id: TFT_FLOAT\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "\twhile inferring type of node 'cond_41/output/_22'\n",
      "2022-11-03 11:22:54.376653: I tensorflow/stream_executor/cuda/cuda_dnn.cc:384] Loaded cuDNN version 8100\n",
      "2022-11-03 11:22:54.894324: I tensorflow/stream_executor/cuda/cuda_blas.cc:1614] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1302/1302 [==============================] - 62s 44ms/step - loss: 1.6424 - accuracy: 0.4156 - val_loss: 1.3155 - val_accuracy: 0.5065\n",
      "Epoch 2/15\n",
      "1302/1302 [==============================] - 54s 42ms/step - loss: 1.3198 - accuracy: 0.5253 - val_loss: 1.1582 - val_accuracy: 0.5675\n",
      "Epoch 3/15\n",
      "1302/1302 [==============================] - 56s 43ms/step - loss: 1.1765 - accuracy: 0.5758 - val_loss: 1.0738 - val_accuracy: 0.6020\n",
      "Epoch 4/15\n",
      "1302/1302 [==============================] - 52s 40ms/step - loss: 1.0836 - accuracy: 0.6086 - val_loss: 1.0338 - val_accuracy: 0.6209\n",
      "Epoch 5/15\n",
      "1302/1302 [==============================] - 57s 44ms/step - loss: 1.0345 - accuracy: 0.6335 - val_loss: 1.0212 - val_accuracy: 0.6313\n",
      "Epoch 6/15\n",
      "1302/1302 [==============================] - 54s 41ms/step - loss: 1.0050 - accuracy: 0.6512 - val_loss: 1.0179 - val_accuracy: 0.6361\n",
      "Epoch 7/15\n",
      "1302/1302 [==============================] - 51s 39ms/step - loss: 0.9847 - accuracy: 0.6649 - val_loss: 1.0163 - val_accuracy: 0.6396\n",
      "Epoch 8/15\n",
      "1302/1302 [==============================] - 39s 30ms/step - loss: 0.9706 - accuracy: 0.6756 - val_loss: 1.0181 - val_accuracy: 0.6426\n",
      "Epoch 9/15\n",
      "1302/1302 [==============================] - 35s 27ms/step - loss: 0.9594 - accuracy: 0.6842 - val_loss: 1.0220 - val_accuracy: 0.6440\n",
      "Epoch 10/15\n",
      "1302/1302 [==============================] - 35s 27ms/step - loss: 0.9516 - accuracy: 0.6898 - val_loss: 1.0253 - val_accuracy: 0.6453\n",
      "Epoch 11/15\n",
      "1302/1302 [==============================] - 35s 27ms/step - loss: 0.9463 - accuracy: 0.6943 - val_loss: 1.0283 - val_accuracy: 0.6453\n",
      "Epoch 12/15\n",
      "1302/1302 [==============================] - 35s 27ms/step - loss: 0.9423 - accuracy: 0.6972 - val_loss: 1.0298 - val_accuracy: 0.6450\n",
      "Epoch 13/15\n",
      "1302/1302 [==============================] - 35s 27ms/step - loss: 0.9396 - accuracy: 0.6989 - val_loss: 1.0328 - val_accuracy: 0.6457\n",
      "Epoch 14/15\n",
      "1302/1302 [==============================] - 35s 27ms/step - loss: 0.9377 - accuracy: 0.7013 - val_loss: 1.0341 - val_accuracy: 0.6473\n",
      "Epoch 15/15\n",
      "1302/1302 [==============================] - 35s 27ms/step - loss: 0.9373 - accuracy: 0.7018 - val_loss: 1.0362 - val_accuracy: 0.6467\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fa2690c9a00>"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq2seq_rnn.compile(\n",
    "    optimizer=\"rmsprop\",\n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    metrics=[\"accuracy\"])\n",
    "seq2seq_rnn.fit(train_ds, epochs=15, validation_data=val_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-\n",
      "I will miss you.\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "[start] te voy a [UNK] [end]\n",
      "-\n",
      "How many people are in this room?\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "[start] cuántos personas hay en esta habitación [end]\n",
      "-\n",
      "I think you should do it.\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "[start] creo que deberías hacerlo [end]\n",
      "-\n",
      "The royal wedding was a magnificent occasion.\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "[start] la [UNK] de la era una mujer era [UNK] [end]\n",
      "-\n",
      "I can't finish this today.\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "[start] no puedo hoy esto [end]\n",
      "-\n",
      "I don't think it'll be that easy.\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "[start] no creo que sea fácil [end]\n",
      "-\n",
      "This hat suits me nicely.\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "[start] este sombrero me parece que me [UNK] [end]\n",
      "-\n",
      "This is very bad.\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "[start] esto es muy mal [end]\n",
      "-\n",
      "This is all a big misunderstanding.\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "[start] todo es un gran todo el en su día [end]\n",
      "-\n",
      "Never choose a vocation just because it looks easy.\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "[start] nunca [UNK] una cosa de que yo solo estoy fácil [end]\n",
      "-\n",
      "We already know each other.\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "[start] ya nos ya se nos uno al otro [end]\n",
      "-\n",
      "This isn't a trap.\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "[start] esto no es una en [end]\n",
      "-\n",
      "I bought it at a thrift shop.\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "[start] lo compré en una tienda de [end]\n",
      "-\n",
      "Tom asked Mary for something hot to drink.\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "[start] tom le pidió a mary algo para algo para beber [end]\n",
      "-\n",
      "Wait for the police.\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "[start] espera a la policía [end]\n",
      "-\n",
      "He'll never forgive me.\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "[start] Él me nunca me va a mí [end]\n",
      "-\n",
      "Compare your translation with the one on the blackboard.\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "[start] [UNK] tu la [UNK] en la con [end]\n",
      "-\n",
      "Stop avoiding me.\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "[start] para de [UNK] [end]\n",
      "-\n",
      "It's too difficult for me.\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "[start] es demasiado difícil para mí [end]\n",
      "-\n",
      "Tom did many of the experiments himself.\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "[start] tom hizo muchos de los [UNK] para la [UNK] [end]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "spa_vocab = target_vectorization.get_vocabulary()\n",
    "spa_index_lookup = dict(zip(range(len(spa_vocab)), spa_vocab))\n",
    "max_decoded_sentence_length = 20\n",
    "\n",
    "def decode_sequence(input_sentence):\n",
    "    tokenized_input_sentence = source_vectorization([input_sentence])\n",
    "    decoded_sentence = '[start]'\n",
    "    for i in range(max_decoded_sentence_length):\n",
    "        tokenized_target_sentence = target_vectorization([decoded_sentence])\n",
    "        next_token_prediction = seq2seq_rnn.predict([tokenized_input_sentence, tokenized_target_sentence])\n",
    "        sampled_token_index = np.argmax(next_token_prediction[0, i, :])\n",
    "        sampled_token = spa_index_lookup[sampled_token_index]\n",
    "        decoded_sentence += ' ' + sampled_token\n",
    "        if sampled_token == '[end]':\n",
    "            break\n",
    "    return decoded_sentence\n",
    "\n",
    "test_eng_texts = [pair[0] for pair in test_pairs]\n",
    "for _ in range(20):\n",
    "    input_sentence = random.choice(test_eng_texts)\n",
    "    print('-')\n",
    "    print(input_sentence)\n",
    "    print(decode_sequence(input_sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "  \n",
    "class TransformerEncoder(layers.Layer):\n",
    "    def __init__(self, embed_dim, dense_dim, num_heads, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.embed_dim = embed_dim\n",
    "        self.dense_dim = dense_dim\n",
    "        self.num_heads = num_heads\n",
    "        self.attention = layers.MultiHeadAttention(\n",
    "            num_heads=num_heads, key_dim=embed_dim)\n",
    "        self.dense_proj = keras.Sequential(\n",
    "            [layers.Dense(dense_dim, activation=\"relu\"),\n",
    "             layers.Dense(embed_dim),]\n",
    "        )\n",
    "        self.layernorm_1 = layers.LayerNormalization()\n",
    "        self.layernorm_2 = layers.LayerNormalization()\n",
    "    def call(self, inputs, mask=None):\n",
    "        if mask is not None:\n",
    "            mask = mask[:, tf.newaxis, :]\n",
    "        attention_output = self.attention(\n",
    "            inputs, inputs, attention_mask=mask)\n",
    "        proj_input = self.layernorm_1(inputs + attention_output)\n",
    "        proj_output = self.dense_proj(proj_input)\n",
    "        return self.layernorm_2(proj_input + proj_output)\n",
    "  \n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update({\n",
    "            \"embed_dim\": self.embed_dim,\n",
    "            \"num_heads\": self.num_heads,\n",
    "            \"dense_dim\": self.dense_dim,\n",
    "        })\n",
    "        return config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerDecoder(layers.Layer):\n",
    "    def __init__(self, embed_dim, dense_dim, num_heads, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.embed_dim = embed_dim\n",
    "        self.dense_dim = dense_dim\n",
    "        self.num_heads = num_heads\n",
    "        self.attention_1 = layers.MultiHeadAttention(\n",
    "            num_heads=num_heads, key_dim=embed_dim)\n",
    "        self.attention_2 = layers.MultiHeadAttention(\n",
    "            num_heads=num_heads, key_dim=embed_dim)\n",
    "        self.dense_proj = keras.Sequential(\n",
    "            [layers.Dense(dense_dim, activation=\"relu\"),\n",
    "             layers.Dense(embed_dim),]\n",
    "        )\n",
    "        self.layernorm_1 = layers.LayerNormalization()\n",
    "        self.layernorm_2 = layers.LayerNormalization()\n",
    "        self.layernorm_3 = layers.LayerNormalization()\n",
    "        self.supports_masking = True\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update({\n",
    "            \"embed_dim\": self.embed_dim,\n",
    "            \"num_heads\": self.num_heads,\n",
    "            \"dense_dim\": self.dense_dim,\n",
    "        })\n",
    "        return config\n",
    "\n",
    "    def get_causal_attention_mask(self, inputs):\n",
    "        input_shape = tf.shape(inputs)\n",
    "        batch_size, sequence_length = input_shape[0], input_shape[1]\n",
    "        i = tf.range(sequence_length)[:, tf.newaxis]\n",
    "        j = tf.range(sequence_length)\n",
    "        mask = tf.cast(i >= j, dtype=\"int32\")\n",
    "        mask = tf.reshape(mask, (1, input_shape[1], input_shape[1]))\n",
    "        mult = tf.concat(\n",
    "            [tf.expand_dims(batch_size, -1),\n",
    "             tf.constant([1, 1], dtype=tf.int32)], axis=0)\n",
    "        return tf.tile(mask, mult)\n",
    "\n",
    "    def call(self, inputs, encoder_outputs, mask=None):\n",
    "        causal_mask = self.get_causal_attention_mask(inputs)\n",
    "        if mask is not None:\n",
    "            padding_mask = tf.cast(\n",
    "                mask[:, tf.newaxis, :], dtype=\"int32\")\n",
    "            padding_mask = tf.minimum(padding_mask, causal_mask)\n",
    "        attention_output_1 = self.attention_1(\n",
    "            query=inputs,\n",
    "            value=inputs,\n",
    "            key=inputs,\n",
    "            attention_mask=causal_mask)\n",
    "        attention_output_1 = self.layernorm_1(inputs + attention_output_1)\n",
    "        attention_output_2 = self.attention_2(\n",
    "            query=attention_output_1,\n",
    "            value=encoder_outputs,\n",
    "            key=encoder_outputs,\n",
    "            attention_mask=padding_mask,\n",
    "        )\n",
    "        attention_output_2 = self.layernorm_2(\n",
    "            attention_output_1 + attention_output_2)\n",
    "        proj_output = self.dense_proj(attention_output_2)\n",
    "        return self.layernorm_3(attention_output_2 + proj_output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEmbedding(layers.Layer):\n",
    "    def __init__(self, sequence_length, input_dim, output_dim, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.token_embeddings = layers.Embedding(\n",
    "            input_dim=input_dim, output_dim=output_dim)\n",
    "        self.position_embeddings = layers.Embedding(\n",
    "            input_dim=sequence_length, output_dim=output_dim)\n",
    "        self.sequence_length = sequence_length\n",
    "        self.input_dim = input_dim\n",
    "        self.output_dim = output_dim\n",
    "  \n",
    "    def call(self, inputs):\n",
    "        length = tf.shape(inputs)[-1]\n",
    "        positions = tf.range(start=0, limit=length, delta=1)\n",
    "        embedded_tokens = self.token_embeddings(inputs)\n",
    "        embedded_positions = self.position_embeddings(positions)\n",
    "        return embedded_tokens + embedded_positions\n",
    " \n",
    "    def compute_mask(self, inputs, mask=None):\n",
    "        return tf.math.not_equal(inputs, 0)\n",
    " \n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update({\n",
    "            \"output_dim\": self.output_dim,\n",
    "            \"sequence_length\": self.sequence_length,\n",
    "            \"input_dim\": self.input_dim,\n",
    "        })\n",
    "        return config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_dim = 256 \n",
    "dense_dim = 2048 \n",
    "num_heads = 8 \n",
    "  \n",
    "encoder_inputs = keras.Input(shape=(None,), dtype=\"int64\", name=\"english\")\n",
    "x = PositionalEmbedding(sequence_length, vocab_size, embed_dim)(encoder_inputs)\n",
    "encoder_outputs = TransformerEncoder(embed_dim, dense_dim, num_heads)(x)\n",
    " \n",
    "decoder_inputs = keras.Input(shape=(None,), dtype=\"int64\", name=\"spanish\")\n",
    "x = PositionalEmbedding(sequence_length, vocab_size, embed_dim)(decoder_inputs)\n",
    "x = TransformerDecoder(embed_dim, dense_dim, num_heads)(x, encoder_outputs)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "decoder_outputs = layers.Dense(vocab_size, activation=\"softmax\")(x)\n",
    "transformer = keras.Model([encoder_inputs, decoder_inputs], decoder_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "1302/1302 [==============================] - 46s 34ms/step - loss: 1.6832 - accuracy: 0.4155 - val_loss: 1.3282 - val_accuracy: 0.5108\n",
      "Epoch 2/30\n",
      "1302/1302 [==============================] - 42s 32ms/step - loss: 1.3401 - accuracy: 0.5326 - val_loss: 1.1576 - val_accuracy: 0.5747\n",
      "Epoch 3/30\n",
      "1302/1302 [==============================] - 42s 33ms/step - loss: 1.1833 - accuracy: 0.5846 - val_loss: 1.0813 - val_accuracy: 0.6031\n",
      "Epoch 4/30\n",
      "1302/1302 [==============================] - 44s 33ms/step - loss: 1.0925 - accuracy: 0.6170 - val_loss: 1.0405 - val_accuracy: 0.6247\n",
      "Epoch 5/30\n",
      "1302/1302 [==============================] - 43s 33ms/step - loss: 1.0431 - accuracy: 0.6396 - val_loss: 1.0128 - val_accuracy: 0.6384\n",
      "Epoch 6/30\n",
      "1302/1302 [==============================] - 43s 33ms/step - loss: 1.0107 - accuracy: 0.6560 - val_loss: 1.0021 - val_accuracy: 0.6451\n",
      "Epoch 7/30\n",
      "1302/1302 [==============================] - 42s 33ms/step - loss: 0.9873 - accuracy: 0.6687 - val_loss: 0.9979 - val_accuracy: 0.6495\n",
      "Epoch 8/30\n",
      "1302/1302 [==============================] - 44s 34ms/step - loss: 0.9682 - accuracy: 0.6796 - val_loss: 1.0002 - val_accuracy: 0.6521\n",
      "Epoch 9/30\n",
      "1302/1302 [==============================] - 44s 34ms/step - loss: 0.9519 - accuracy: 0.6884 - val_loss: 0.9931 - val_accuracy: 0.6548\n",
      "Epoch 10/30\n",
      "1302/1302 [==============================] - 43s 33ms/step - loss: 0.9379 - accuracy: 0.6957 - val_loss: 0.9935 - val_accuracy: 0.6581\n",
      "Epoch 11/30\n",
      "1302/1302 [==============================] - 44s 34ms/step - loss: 0.9233 - accuracy: 0.7033 - val_loss: 0.9920 - val_accuracy: 0.6615\n",
      "Epoch 12/30\n",
      "1302/1302 [==============================] - 44s 34ms/step - loss: 0.9107 - accuracy: 0.7091 - val_loss: 0.9961 - val_accuracy: 0.6584\n",
      "Epoch 13/30\n",
      "1302/1302 [==============================] - 43s 33ms/step - loss: 0.8974 - accuracy: 0.7149 - val_loss: 0.9897 - val_accuracy: 0.6624\n",
      "Epoch 14/30\n",
      "1302/1302 [==============================] - 44s 34ms/step - loss: 0.8847 - accuracy: 0.7204 - val_loss: 1.0037 - val_accuracy: 0.6541\n",
      "Epoch 15/30\n",
      "1302/1302 [==============================] - 45s 34ms/step - loss: 0.8755 - accuracy: 0.7248 - val_loss: 1.0027 - val_accuracy: 0.6637\n",
      "Epoch 16/30\n",
      "1302/1302 [==============================] - 44s 34ms/step - loss: 0.8644 - accuracy: 0.7293 - val_loss: 1.0155 - val_accuracy: 0.6611\n",
      "Epoch 17/30\n",
      "1302/1302 [==============================] - 44s 34ms/step - loss: 0.8529 - accuracy: 0.7333 - val_loss: 1.0033 - val_accuracy: 0.6636\n",
      "Epoch 18/30\n",
      "1302/1302 [==============================] - 44s 34ms/step - loss: 0.8451 - accuracy: 0.7373 - val_loss: 1.0168 - val_accuracy: 0.6637\n",
      "Epoch 19/30\n",
      "1302/1302 [==============================] - 44s 34ms/step - loss: 0.8343 - accuracy: 0.7416 - val_loss: 1.0209 - val_accuracy: 0.6651\n",
      "Epoch 20/30\n",
      "1302/1302 [==============================] - 44s 34ms/step - loss: 0.8246 - accuracy: 0.7451 - val_loss: 1.0173 - val_accuracy: 0.6652\n",
      "Epoch 21/30\n",
      "1302/1302 [==============================] - 44s 34ms/step - loss: 0.8154 - accuracy: 0.7475 - val_loss: 1.0310 - val_accuracy: 0.6601\n",
      "Epoch 22/30\n",
      "1302/1302 [==============================] - 44s 34ms/step - loss: 0.8084 - accuracy: 0.7512 - val_loss: 1.0302 - val_accuracy: 0.6614\n",
      "Epoch 23/30\n",
      "1302/1302 [==============================] - 44s 34ms/step - loss: 0.7999 - accuracy: 0.7546 - val_loss: 1.0394 - val_accuracy: 0.6593\n",
      "Epoch 24/30\n",
      "1302/1302 [==============================] - 44s 34ms/step - loss: 0.7909 - accuracy: 0.7572 - val_loss: 1.0460 - val_accuracy: 0.6602\n",
      "Epoch 25/30\n",
      "1302/1302 [==============================] - 44s 34ms/step - loss: 0.7814 - accuracy: 0.7602 - val_loss: 1.0484 - val_accuracy: 0.6608\n",
      "Epoch 26/30\n",
      "1302/1302 [==============================] - 44s 34ms/step - loss: 0.7775 - accuracy: 0.7624 - val_loss: 1.0511 - val_accuracy: 0.6664\n",
      "Epoch 27/30\n",
      "1302/1302 [==============================] - 44s 34ms/step - loss: 0.7708 - accuracy: 0.7647 - val_loss: 1.0555 - val_accuracy: 0.6616\n",
      "Epoch 28/30\n",
      "1302/1302 [==============================] - 44s 34ms/step - loss: 0.7624 - accuracy: 0.7678 - val_loss: 1.0634 - val_accuracy: 0.6608\n",
      "Epoch 29/30\n",
      "1302/1302 [==============================] - 44s 34ms/step - loss: 0.7550 - accuracy: 0.7698 - val_loss: 1.0482 - val_accuracy: 0.6646\n",
      "Epoch 30/30\n",
      "1302/1302 [==============================] - 44s 34ms/step - loss: 0.7494 - accuracy: 0.7716 - val_loss: 1.0751 - val_accuracy: 0.6577\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fa26a56f3a0>"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformer.compile(\n",
    "    optimizer=\"rmsprop\",\n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    metrics=[\"accuracy\"])\n",
    "transformer.fit(train_ds, epochs=30, validation_data=val_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-\n",
      "Don't rely too much on your guidebook.\n",
      "[start] no te [UNK] mucho en tu [UNK] [end]\n",
      "-\n",
      "The movie is showing in movie theaters next month.\n",
      "[start] la película me está pasando en la [UNK] del mes que viene [end]\n",
      "-\n",
      "Seicho Matumoto died in 1992.\n",
      "[start] la [UNK] de la sala de [UNK] [end]\n",
      "-\n",
      "That child wants some friends to play with.\n",
      "[start] ese niño quiere algunos amigos con al juego [end]\n",
      "-\n",
      "I thought Tom would show up.\n",
      "[start] pensé que tom [UNK] [end]\n",
      "-\n",
      "My father stopped smoking.\n",
      "[start] mi padre se ha de fumar [end]\n",
      "-\n",
      "This chair is soft and comfortable.\n",
      "[start] esta silla está se de de de de de de de lo [UNK] [end]\n",
      "-\n",
      "Tom'll find out.\n",
      "[start] tom [UNK] [end]\n",
      "-\n",
      "After the game, he went straight home to feed his dog.\n",
      "[start] después de que él se fue [UNK] dar a su perro de comer [end]\n",
      "-\n",
      "Tom has three adult sons.\n",
      "[start] tomás tiene tres hijos más que hijos [end]\n",
      "-\n",
      "Tom wouldn't know.\n",
      "[start] tomás no se lo sabe [end]\n",
      "-\n",
      "Let's play baseball.\n",
      "[start] vamos a jugar al béisbol [end]\n",
      "-\n",
      "Somebody answered.\n",
      "[start] alguien respondió [end]\n",
      "-\n",
      "He heard a strange noise, so he jumped out of bed.\n",
      "[start] Él oyó un extraño así que se fue de la cama [end]\n",
      "-\n",
      "Now, how can I help you?\n",
      "[start] ahora cómo te puedo ayudar [end]\n",
      "-\n",
      "Cats hate to get wet.\n",
      "[start] los gatos se [UNK] [end]\n",
      "-\n",
      "Tom asked Mary to warm up some leftovers.\n",
      "[start] tom le pidió a mary que [UNK] unas vista [end]\n",
      "-\n",
      "I am very glad to hear of your success.\n",
      "[start] estoy muy feliz de escuchar de tu éxito [end]\n",
      "-\n",
      "I never thought I would have to support such a large family.\n",
      "[start] nunca pensé que estaría a de [end]\n",
      "-\n",
      "Can I buy you a drink?\n",
      "[start] puedo comprar una bebida [end]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "spa_vocab = target_vectorization.get_vocabulary()\n",
    "spa_index_lookup = dict(zip(range(len(spa_vocab)), spa_vocab))\n",
    "max_decoded_sentence_length = 20 \n",
    "  \n",
    "def decode_sequence(input_sentence):\n",
    "    tokenized_input_sentence = source_vectorization([input_sentence])\n",
    "    decoded_sentence = \"[start]\" \n",
    "    for i in range(max_decoded_sentence_length):\n",
    "        tokenized_target_sentence = target_vectorization(\n",
    "            [decoded_sentence])[:, :-1]\n",
    "        predictions = transformer(\n",
    "            [tokenized_input_sentence, tokenized_target_sentence])\n",
    "        sampled_token_index = np.argmax(predictions[0, i, :])\n",
    "        sampled_token = spa_index_lookup[sampled_token_index]\n",
    "        decoded_sentence += \" \" + sampled_token\n",
    "        if sampled_token == \"[end]\":\n",
    "            break\n",
    "    return decoded_sentence\n",
    "  \n",
    "test_eng_texts = [pair[0] for pair in test_pairs] \n",
    "for _ in range(20):\n",
    "    input_sentence = random.choice(test_eng_texts)\n",
    "    print(\"-\")\n",
    "    print(input_sentence)\n",
    "    print(decode_sequence(input_sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('tf')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3c4321ab1b242d2e066d5c4b9cff33f957cb21b09244bbe06e7a100233295ac7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
